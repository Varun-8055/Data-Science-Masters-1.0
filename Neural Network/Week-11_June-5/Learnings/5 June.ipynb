{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fa3361-b606-492b-aa31-7f708c9cf0dd",
   "metadata": {},
   "source": [
    "# Tensorflow-2.x \n",
    "\n",
    "<img src=\"https://i.ytimg.com/vi/yjprpOoH5c8/maxresdefault.jpg\" width=\"600\" \n",
    "     height=\"300\">\n",
    "     \n",
    "TensorFlow is an open source software library for high performance numerical computation. Its flexible architecture allows easy deployment of computation across a variety of platforms (CPUs, GPUs, TPUs), and from desktops to clusters of servers to mobile and edge devices. Originally developed by researchers and engineers from the Google Brain team within Google’s AI organization, it comes with strong support for machine learning and deep learning and the flexible numerical computation core is used across many other scientific domains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f202364-8ce8-4443-b6ff-ce1cd58cab85",
   "metadata": {},
   "source": [
    "## Why Tensorflow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6c1c8-45c6-433d-80b2-35585776b09e",
   "metadata": {},
   "source": [
    "<img src=\"https://www.imaginarycloud.com/blog/content/images/2021/04/pytorchvs_cover.png\" width=\"600\" \n",
    "     height=\"300\">\n",
    "     \n",
    "TensorFlow is a popular and widely used open-source machine learning framework developed by Google. It offers a range of features and benefits that make it a powerful tool for building and deploying machine learning models. Here are some reasons why TensorFlow is commonly used:\n",
    "\n",
    "- Flexibility: TensorFlow provides a flexible and modular architecture that allows developers to build and customize machine learning models for a wide variety of tasks. It supports both high-level and low-level APIs, giving users the flexibility to work at different levels of abstraction.\n",
    "\n",
    "- Scalability: TensorFlow is designed to handle large-scale machine learning projects. It enables efficient distributed computing across multiple CPUs and GPUs, making it suitable for training models on large datasets.\n",
    "\n",
    "- Wide range of applications: TensorFlow can be used for a diverse range of machine learning tasks, including image and speech recognition, natural language processing, recommendation systems, and more. It supports various neural network architectures, such as convolutional neural networks (CNNs), recurrent neural networks (RNNs), and transformers.\n",
    "\n",
    "- Community and ecosystem: TensorFlow has a large and active community of developers, researchers, and enthusiasts. This community contributes to the development of the framework by sharing code, providing support, and creating libraries and tools that extend TensorFlow's functionality. This vibrant ecosystem makes it easier to find resources, tutorials, and pre-trained models.\n",
    "\n",
    "- Visualization and debugging: TensorFlow includes tools for visualizing and debugging models, which can aid in understanding the behavior of the model during training and inference. It provides built-in support for TensorBoard, a web-based tool for visualizing metrics, model graphs, and other aspects of the training process.\n",
    "\n",
    "- Deployment options: TensorFlow offers multiple deployment options, allowing models to be deployed in a variety of environments. It supports deployment on different platforms, including desktops, servers, mobile devices, and even specialized hardware such as Google's Tensor Processing Units (TPUs).\n",
    "\n",
    "- Integration with other libraries and frameworks: TensorFlow can be easily integrated with other popular libraries and frameworks in the Python ecosystem, such as NumPy, Pandas, and scikit-learn. This enables seamless data manipulation, preprocessing, and post-processing tasks in conjunction with TensorFlow's capabilities.\n",
    "\n",
    "- Continued development and support: TensorFlow is actively developed and maintained by Google and the TensorFlow community. Regular updates and improvements ensure that the framework stays up to date with the latest advancements in machine learning research and industry practices.\n",
    "\n",
    "These are just a few reasons why TensorFlow is a popular choice for machine learning tasks. However, it's worth noting that the choice of framework ultimately depends on the specific requirements and preferences of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b3ade-75f8-4606-b07e-b073f1266453",
   "metadata": {},
   "source": [
    "## Installation of Tensorflow\n",
    "\n",
    "#### TensorFlow is tested and supported on the following 64-bit systems:\n",
    "\n",
    "1.Ubuntu 16.04 or later\n",
    "\n",
    "2.Windows 7 or later\n",
    "\n",
    "3.macOS 10.12.6 (Sierra) or later (no GPU support)\n",
    "\n",
    "4.Raspbian 9.0 or later\n",
    "\n",
    "#### For installing latest version of Tensorflow\n",
    "    pip install tensorflow\n",
    "\n",
    "    To run from Anaconda Prompt\n",
    "\n",
    "    !pip install tensorflow\n",
    "\n",
    "    To run from Jupyter Notebook\n",
    "\n",
    "#### For installing a specific version of Tensorflow\n",
    "    pip install tensorflow==2.x\n",
    "\n",
    "    To run from Anaconda Prompt\n",
    "\n",
    "    !pip install tensorflow==2.x\n",
    " \n",
    "    To run from Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cf632-df65-408d-be25-9498895a6914",
   "metadata": {},
   "source": [
    "Both Tensorflow 2.0 and Keras have been released for four years (Keras was released in March 2015, and Tensorflow was released in November of the same year). The rapid development of deep learning in the past days, we also know some problems of Tensorflow1.x and Keras:\n",
    "\n",
    "- Using Tensorflow means programming static graphs, which is difficult and inconvenient for programs that are familiar with imperative programming\n",
    "- Tensorflow api is powerful and flexible, but it is more complex, confusing and difficult to use.\n",
    "- Keras api is productive and easy to use, but lacks flexibility for research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df29f1e-a9f7-417f-b240-08b7cdd56aa0",
   "metadata": {},
   "source": [
    "## Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b22d00a-1581-4180-be64-e42549b8de0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n",
      "Eager execution is: True\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras._tf_keras.keras' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow version: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tf\u001b[38;5;241m.\u001b[39m__version__))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEager execution is: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(tf\u001b[38;5;241m.\u001b[39mexecuting_eagerly()))\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras version: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras._tf_keras.keras' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution is: {}\".format(tf.executing_eagerly()))\n",
    "print(\"Keras version: {}\".format(tf.keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111b4cbd-dd60-4158-b1c7-db15ad389129",
   "metadata": {},
   "source": [
    "Tensorflow2.0 is a combination design of Tensorflow1.x and Keras. Considering user feedback and framework development over the past four years, it largely solves the above problems and will become the future machine learning platform.\n",
    "\n",
    "Tensorflow 2.0 is built on the following core ideas:\n",
    "\n",
    "- The coding is more pythonic, so that users can get the results immediately like they are programming in numpy\n",
    "- Retaining the characteristics of static graphs (for performance, distributed, and production deployment), this makes TensorFlow fast, scalable, and ready for production.\n",
    "- Using Keras as a high-level API for deep learning, making Tensorflow easy to use and efficient\n",
    "- Make the entire framework both high-level features (easy to use, efficient, and not flexible) and low-level features (powerful and scalable, not easy to use, but very flexible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4a856-dc3f-4f1c-9f99-1c584f69e549",
   "metadata": {},
   "source": [
    "Eager execution is the default in TensorFlow 2 and, as such, needs no special setup. The following code can be used to find out whether a CPU or GPU is in use and if it's a GPU, whether that GPU is #0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cfb400-48eb-44a3-a044-7ed65dc2472c",
   "metadata": {},
   "source": [
    "## GPU/CPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc4602a7-b5e5-48e5-92e3-d6cf1bbf1dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_3869/3803036092.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Running on CPU\n"
     ]
    }
   ],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    print('Running on GPU')\n",
    "else:\n",
    "    print('Running on CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c101189c-c37c-457f-b354-742915669f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36e87699-3dd8-464f-89e5-7037ca876ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90fb92-ea4e-45cb-9a21-bb9b653fdbe0",
   "metadata": {},
   "source": [
    "## Tensor Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e575ceb5-09b4-4c32-942d-84d34725c776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron = tf.constant(42)\n",
    "ineuron   # shape is nothing because it is a scaler quantity  numoy= value in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02c00eff-72c0-42a5-81f9-6bf780925ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron.numpy()  # numpy method helps in extracting the value directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50cce526-4614-4e39-800b-fe50a642198b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron1 = tf.constant(1, dtype = tf.int64)\n",
    "ineuron1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae4c314-745f-49e8-afa7-42afa8f774cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 2]\n",
      " [9 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ineuron_x = tf.constant([[4,2],[9,5]])  # metrix form \n",
    "print(ineuron_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5079607e-90c9-4812-97bc-5942f168f16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 2],\n",
       "       [9, 5]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron_x.numpy()  # extract the matrix values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c41522cb-3c87-45f6-b85a-da9571807a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print('shape:',ineuron_x.shape)\n",
    "print(ineuron_x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b917dcd9-41ba-476d-a89d-383fb6aaa412",
   "metadata": {},
   "source": [
    "### Commonly used method is to generate constant tf.ones and the tf.zeros like of numpy np.ones & np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89599cfe-4e65-4794-9dda-a8b51b29a680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.ones(shape=(2,3)))  # matrix of 2 rows and 3 columns filled with 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "814e09ae-cd34-402f-aa32-6e23dd71c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.zeros(shape=(3,2)))  # matrix of 3 rows and 2 columns filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c093b1c5-4cd2-409a-8de8-402e8f0c685c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 6 8]\n",
      " [4 6 8]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "const2 = tf.constant([[3,4,5], [3,4,5]])  \n",
    "const1 = tf.constant([[1,2,3], [1,2,3]])\n",
    "result = tf.add(const1, const2)  #addition of 2 metrices\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9ad3ae-ad30-4950-a45a-6e87040b49bf",
   "metadata": {},
   "source": [
    "We have defined two constants and we add one value to the other. As a result, we got a Tensor object with the result of the adding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcaaad5-9602-4603-a896-d2fa9a567d0f",
   "metadata": {},
   "source": [
    "### Random constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96a70eb7-b1a8-4e9f-834b-342959c635fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 0.47414666,  0.6018374 ],\n",
       "       [-0.10887955, -2.5275571 ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(2,2),mean=0,stddev=1.0)   # given the standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4c659de-2c6e-41e6-b764-ed56ca8c916f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[8, 1],\n",
       "       [3, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape=(2,2),minval=0,maxval=10,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f36e9a-1ae2-4759-8e13-000bf3779476",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "A variable is a special tensor that is used to store variable values ​​and needs to be initialized with some values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe19c9b-1acd-4b3c-8e86-5699d0f9739f",
   "metadata": {},
   "source": [
    "## Declaring variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85dacb3b-b0a1-4b6e-b332-1d6307469fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>,\n",
       " <tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
       " array([[[ 0.,  1.,  2.],\n",
       "         [ 3.,  4.,  5.]],\n",
       " \n",
       "        [[ 6.,  7.,  8.],\n",
       "         [ 9., 10., 11.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var0 = 24 # python variable\n",
    "var1 = tf.Variable(42) # rank 0 tensor\n",
    "var2 = tf.Variable([ [ [0., 1., 2.], [3., 4., 5.] ], [ [6., 7., 8.], [9., 10., 11.] ] ]) #rank 3 tensor\n",
    "# rank is the no of indices i'll make to particularly point to a particular value.\n",
    "var0, var1, var2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49252a94-5345-47ce-b339-e9da8c08145b",
   "metadata": {},
   "source": [
    "\n",
    "TensorFlow will infer the datatype, defaulting to tf.float32 for floats and tf.int32 for integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c80b3-e4d5-405e-a851-333f00506004",
   "metadata": {},
   "source": [
    "### The datatype can be explicitly specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71baed5f-597c-40ec-b944-b416d0903b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_var64 = tf.Variable(89, dtype = tf.float64)\n",
    "float_var64.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f1d70-467d-4c56-9a99-622cc70f9c21",
   "metadata": {},
   "source": [
    "TensorFlow has a large number of built-in datatypes.\n",
    "\n",
    "- datatype\tdescription\n",
    "- tf.float16: \t16-bit half-precision floating-point.\n",
    "- tf.float32:\t32-bit single-precision floating-point.\n",
    "- tf.float64:\t64-bit double-precision floating-point.\n",
    "- tf.bfloat16:\t16-bit truncated floating-point.\n",
    "- tf.complex64:\t64-bit single-precision complex.\n",
    "- tf.complex128:\t128-bit double-precision complex.\n",
    "- tf.int8:\t8-bit signed integer.\n",
    "- tf.uint8:\t8-bit unsigned integer.\n",
    "- tf.uint16:\t16-bit unsigned integer.\n",
    "- tf.uint32:\t32-bit unsigned integer.\n",
    "- tf.uint64:\t64-bit unsigned integer.\n",
    "- tf.int16:\t16-bit signed integer.\n",
    "- tf.int32:\t32-bit signed integer.\n",
    "- tf.int64:\t64-bit signed integer.\n",
    "- tf.bool:\tBoolean.\n",
    "- tf.string:\tString.\n",
    "- tf.qint8:\tQuantized 8-bit signed integer.\n",
    "- tf.quint8:\tQuantized 8-bit unsigned integer.\n",
    "- tf.qint16:\tQuantized 16-bit signed integer.\n",
    "- tf.quint16:\tQuantized 16-bit unsigned integer.\n",
    "- tf.qint32:\tQuantized 32-bit signed integer.\n",
    "- tf.resource:\tHandle to a mutable resource.\n",
    "- tf.variant:\tValues of arbitrary types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec1526-8dea-4008-82e3-e977557b7be5",
   "metadata": {},
   "source": [
    "### To reassign a variable, use var.assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6de2ba9-9a71-4175-9bbe-ad10072f2419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=89.0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_reassign = tf.Variable(89.)\n",
    "var_reassign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05724226-1d66-4bc6-85cb-3af8291ab3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=98.0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_reassign.assign(98.)\n",
    "var_reassign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17bdc5f5-3788-4beb-9ed4-ab69b5018e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[-1.3756553 , -0.4510613 ],\n",
      "       [-0.34079346,  0.13692687]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "initial_value = tf.random.normal(shape=(2,2))  \n",
    "a = tf.Variable(initial_value)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb11c9-b9c7-4be9-b380-b9821337e858",
   "metadata": {},
   "source": [
    " We can assign \"=\" with assign (value), or assign_add (value) with \"+ =\", or assign_sub (value) with \"-=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a606736-f8f7-4329-8d25-fd8ffc75d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_value = tf.random.normal(shape=(2, 2))  # Its not specify but we will assume it as a standard normal distribution\n",
    "a.assign(new_value)  # assign new_value to a \n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        assert a[i, j] == new_value[i, j]  # so all new_value is equal to a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a63f619f-45b8-4099-b09d-73072b835258",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_value = tf.random.normal(shape=(2,2))\n",
    "a.assign_add(added_value)  # we can also add to the existing value\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        assert a[i,j] == new_value[i,j]+added_value[i,j]  # it will check whether both variable is equal after adding\n",
    "        # assert means if condition is true is passes on otherwise it gives assertion error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad75b7c-dd0a-4d6f-93b9-aadd4b5c36e3",
   "metadata": {},
   "source": [
    "### Shaping a tensor\n",
    "\n",
    "model architecture is very shape dependent so it is necessary to do shaping of tensor\n",
    "\n",
    "for ex: ANN takes only 1-d vector not 2-d vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8edcf88-d4e1-407d-8629-2e0d8dab62cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.Variable([ [ [0., 1., 2.], [3., 4., 5.] ], [ [6., 7., 8.], [9., 10., 11.] ] ]) # tensor variable\n",
    "print(tensor.shape)  # total 12 elements into the 2*2*3 matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326906a7-3dd3-4283-a72d-4082fea244b8",
   "metadata": {},
   "source": [
    "### Tensors may be reshaped and retain the same values, as is often required for constructing neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "395a16dc-490c-4a38-ae07-b6a091ee87c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.,  9., 10., 11.]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = tf.reshape(tensor,[2,6]) # 2 rows 6 cols    # total 12 elements\n",
    "tensor2 = tf.reshape(tensor,[1,12]) # 1 rows 12 cols  # total 12 elements\n",
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a339926a-86f3-4890-8b99-6eddc11f5e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = tf.reshape(tensor,[1,12]) # 1 row 12 columns\n",
    "tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680fd61-7e70-4970-8641-8e53167de2af",
   "metadata": {},
   "source": [
    "### Ranking (dimensions) of a tensor\n",
    "The rank of a tensor is the number of dimensions it has, that is, the number of indices that are required to specify any particular element of that tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "530c05d7-a0ac-452f-b3e3-95bc66296019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.rank(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83380999-666e-4888-ace6-4e650ef42a50",
   "metadata": {},
   "source": [
    "(the shape is () because the output here is a scalar value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b792e-bb17-42d8-b214-c774dce15a0a",
   "metadata": {},
   "source": [
    "### Specifying an element of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd8c7eec-0bdc-4f55-9bc1-395e3af3cc1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = tensor[1, 0, 2] # slice 1, row 0, column 2\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d9fe0-736d-49c0-bf67-a348cd23438a",
   "metadata": {},
   "source": [
    "### Casting a tensor to a NumPy/Python variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34bd171f-1c25-42b8-9cc8-2d9ee76288a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  1.  2.]\n",
      "  [ 3.  4.  5.]]\n",
      "\n",
      " [[ 6.  7.  8.]\n",
      "  [ 9. 10. 11.]]]\n"
     ]
    }
   ],
   "source": [
    "# all function that are applicable onto the numpy array is also applicable to the tensor variable\n",
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8786441-f87d-43e0-b8a9-9c133472dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "print(tensor[1, 0, 2].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfad34-a809-4ad7-8bfb-f3e64ee97966",
   "metadata": {},
   "source": [
    "### Finding the size (number of elements) of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "075586f0-5eb4-4879-b83c-a34a119d1ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_size = tf.size(input=tensor).numpy()\n",
    "tensor_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4d136e6-f9e5-4eb3-acf8-9e69c26a7de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the datatype of a tensor\n",
    "tensor3.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f48c67-805d-4b4e-800b-45233c45f906",
   "metadata": {},
   "source": [
    "### Tensorflow mathematical operations\n",
    "Can be used as numpy for artificial operations. Tensorflow can not execute these operations on the GPU or TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e3282cb-4e01-43b5-9e06-fe1785f15655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.4066152  -0.7991067 ]\n",
      " [-1.1373041   0.17776893]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.09265962 -0.34313217]\n",
      " [-0.2617848  -0.67561287]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.31395558 -1.1422389 ]\n",
      " [-1.3990889  -0.49784392]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.0985681  1.3047096 ]\n",
      " [1.9574497  0.24784857]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.3688289  0.3191038 ]\n",
      " [0.24682175 0.6078398 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "c = a+b\n",
    "d = tf.square(c)\n",
    "e = tf.exp(c)  # exponential\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d34538-d804-4e6f-bb34-3bd8736bd526",
   "metadata": {},
   "source": [
    "### Performing element-wise primitive tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "58ad4fee-3d05-4752-9eca-ee7a45a203ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
       "array([[[  0.,   1.,   4.],\n",
       "        [  9.,  16.,  25.]],\n",
       "\n",
       "       [[ 36.,  49.,  64.],\n",
       "        [ 81., 100., 121.]]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*tensor # multiplication of a tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ca7c0-3ef2-4d1c-a8cf-bf29dfc61a7b",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "Element-wise tensor operations support broadcasting in the same way that NumPy arrays do.\n",
    "\n",
    "The simplest example is that of multiplying a tensor by a scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37902a54-7e0f-4dda-8fd5-feba01c68e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.  4.  8.]\n",
      "  [12. 16. 20.]]\n",
      "\n",
      " [[24. 28. 32.]\n",
      "  [36. 40. 44.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor4 = tensor*4  # tensor has a shape but scalar is not having any shape \n",
    "print(tensor4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc218b7-3ea3-43bc-bb48-b7cbcaa86654",
   "metadata": {},
   "source": [
    "the scalar multiplier 4 is—conceptually, at least—expanded into an array that can be multiplied element-wise with t2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123ea30-25bc-495c-81d3-a3e339e7a2cd",
   "metadata": {},
   "source": [
    "### Transpose Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc55b093-8d16-4e37-867a-0a5c0d9dd0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[14]], dtype=int32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_u = tf.constant([[3,4,3]])\n",
    "matrix_v = tf.constant([[1,2,1]])\n",
    "# column of first matrix should match the row of second matrix\n",
    "tf.matmul(matrix_u, tf.transpose(a=matrix_v))  # proper multiplication of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b96aa3-5795-4022-8648-977c1ca9b227",
   "metadata": {},
   "source": [
    "### Casting a tensor to another (tensor) datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56201595-553f-44d3-8175-856c244aba96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11]], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.cast(tensor1, dtype=tf.int32)  # tensor variable is bydefault float, we are casting into int\n",
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273e7855-39cd-444c-aa42-2827d35bfa4d",
   "metadata": {},
   "source": [
    "### With truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "282eb393-465c-4239-9c93-50606ad73358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = tf.cast(tf.constant(4.9), dtype=tf.int32)  # float to int \n",
    "j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277900a-3a6c-48e5-a375-405dba83b85f",
   "metadata": {},
   "source": [
    "### Declaring Ragged tensors\n",
    "A ragged tensor is a tensor with one or more ragged dimensions. Ragged dimensions are dimensions that have slices that may have different lengths.There are a variety of methods for declaring ragged arrays, the simplest being a constant ragged array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f2d20-c019-4656-b352-f23c604b86f6",
   "metadata": {},
   "source": [
    "### The following example shows how to declare a constant ragged array and the lengths of the individual slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b93cacb-6519-48bd-8bb2-6dadb152e460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[5, 2, 6, 1], [], [4, 10, 7], [8], [6, 7]]>\n",
      "tf.Tensor([5 2 6 1], shape=(4,), dtype=int32)\n",
      "tf.Tensor([], shape=(0,), dtype=int32)\n",
      "tf.Tensor([ 4 10  7], shape=(3,), dtype=int32)\n",
      "tf.Tensor([8], shape=(1,), dtype=int32)\n",
      "tf.Tensor([6 7], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# usually tensor have same no of rows and columns into entire variable but ragged tensor can have variables of any length\n",
    "ragged =tf.ragged.constant([[5, 2, 6, 1], [], [4, 10, 7], [8], [6,7]])\n",
    "\n",
    "print(ragged)\n",
    "print(ragged[0,:])\n",
    "print(ragged[1,:])\n",
    "print(ragged[2,:])\n",
    "print(ragged[3,:])\n",
    "print(ragged[4,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2778d6-1c47-4551-9d32-8c9994d8ed8e",
   "metadata": {},
   "source": [
    "### Finding the squared difference between two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11860176-f66f-46c0-bb94-46cfe536afb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([16,  4,  0,  4, 36], dtype=int32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varx = [1,3,5,7,11]\n",
    "vary = 5   # broadcasting concept here also\n",
    "varz = tf.math.squared_difference(varx,vary)\n",
    "varz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91070dc-1d5b-4501-a3b6-eed0b070a75b",
   "metadata": {},
   "source": [
    "The Python variables, varx and vary, are cast into tensors and that vary is then broadcast across varx in this example. So, for example, the first calculation is (1-5)2 = 16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec57b9-19a5-4234-b0af-333b28f7144b",
   "metadata": {},
   "source": [
    "### Finding the mean\n",
    "The following is the signature of tf.reduce_mean()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d473e-cd4d-46c6-8410-f264c64c193d",
   "metadata": {},
   "source": [
    "Note that this is equivalent to np.mean, except that it infers the return datatype from the input tensor, whereas np.mean allows you to specify the output type (defaulting to float64):\n",
    "\n",
    "tf.reduce_mean(input_tensor, axis=None, keepdims=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "90c85872-e90e-42eb-b5a9-d7a3bdd42b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a constant\n",
    "numbers = tf.constant([[4., 5.], [7., 3.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4cf1e-6b9e-4dff-ad40-a1bd62a0cb9c",
   "metadata": {},
   "source": [
    "### Find the mean across all axes (use the default axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e073b62a-66d1-4f41-a128-b71810e23b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=4.75>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers)\n",
    "#( 4. + 5. + 7. + 3.)/4 = 4.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd411a13-0681-4d9d-be86-1dff8756277b",
   "metadata": {},
   "source": [
    "### Find the mean across columns (that is, reduce rows) with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a339776-f674-429c-b7b4-649be43b4439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([5.5, 4. ], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers, axis=0) # [ (4. + 7. )/2 , (5. + 3.)/2 ] = [5.5, 4.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebdb225-0368-413b-8148-d287e21fb437",
   "metadata": {},
   "source": [
    "### When keepdims is True, the reduced axis is retained with a length of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d7f9fb22-6f4f-4c70-bbdc-5bed0f381243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[5.5, 4. ]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when we find the mean across rows, we usually lose one dimension.keepdims=True will keep the rank of variable as it is. \n",
    "tf.reduce_mean(input_tensor=numbers, axis=0, keepdims=True) # we still need 2 indices to get value 5.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226d1a7-fd45-4d84-ad8f-5414ca661926",
   "metadata": {},
   "source": [
    "### Find the mean across rows (that is, reduce columns) with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e08703ad-bcf9-4656-8052-18244606e9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([4.5, 5. ], dtype=float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers, axis=1) # [ (4. + 5. )/2 , (7. + 3. )/2] = [4.5, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8198b2-bf3e-45b5-903f-c9dd3f9644a6",
   "metadata": {},
   "source": [
    "### When keepdims is True, the reduced axis is retained with a length of 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adc2e8c4-e254-414e-a2c2-76de20702eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[4.5],\n",
       "       [5. ]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(input_tensor=numbers, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6468e2a-4548-49bc-8ef3-639cc5231acd",
   "metadata": {},
   "source": [
    "### Generating tensors filled with random values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c4520-b384-44c3-b41a-975f83bd5d4c",
   "metadata": {},
   "source": [
    "### Using tf.random.normal()\n",
    "\n",
    "- tf.random.normal() outputs a tensor of the given shape filled with values of the dtype type from a normal distribution.\n",
    "\n",
    "The required signature is as follows:\n",
    "\n",
    "- tf. random.normal(shape, mean = 0, stddev =2, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f051ad43-27f7-4c34-b792-714b40aa22ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 8.425528   7.8421144]\n",
      " [10.246982  11.073094 ]\n",
      " [ 9.410436   8.674204 ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# using seed : we are able to generate or recall same set of values again and again.\n",
    "tf.random.normal(shape = (3,2), mean=10, stddev=2, dtype=tf.float32, seed=None, name=None)\n",
    "ran = tf.random.normal(shape = (3,2), mean=10.0, stddev=2.0)\n",
    "print(ran)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4d6eed-b622-4fc4-8767-20be99f5ba33",
   "metadata": {},
   "source": [
    "### Using tf.random.uniform()\n",
    "The required signature is this:\n",
    "\n",
    "- tf.random.uniform(shape, minval = 0, maxval= None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f0c46-1661-4f2c-85b1-3f3804fdc5f1",
   "metadata": {},
   "source": [
    "This outputs a tensor of the given shape filled with values from a uniform distribution in the range minval to maxval, where the lower bound is inclusive but the upper bound isn't. Take this, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6119055a-85de-4fc8-8af7-7617f9b79f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       "array([[0.66447365, 0.90878725, 0.4470594 , 0.02682722],\n",
       "       [0.7226206 , 0.33726835, 0.07501733, 0.09808552]], dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.uniform(shape = (2,4), minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c64f9-5000-409a-8fa8-d27ca55deb3e",
   "metadata": {},
   "source": [
    "### Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58b09bf3-eedb-44ba-ba7b-9910639b5bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 6]\n",
      " [5 2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 7]\n",
      " [9 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(11) # we are generating same type of values everytime.If we dont set it we get differ. values everytime\n",
    "ran1 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "ran2 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "print(ran1) #Call 1\n",
    "print(ran2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf5b3c59-65e0-435f-9739-88732673fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4 6]\n",
      " [5 2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 7]\n",
      " [9 4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(11) #same seed\n",
    "ran1 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "ran2 = tf.random.uniform(shape = (2,2), maxval=10, dtype = tf.int32)\n",
    "print(ran1) #Call 2\n",
    "print(ran2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7226fad4-1f19-4942-8048-84ee8d12bbe6",
   "metadata": {},
   "source": [
    "### Practical example of Random values using Dices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb5f267c-d949-48a1-8f76-6c712b22d010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 5  5 10]\n",
      " [ 4  3  7]\n",
      " [ 5  3  8]\n",
      " [ 3  3  6]\n",
      " [ 1  4  5]\n",
      " [ 4  1  5]\n",
      " [ 5  1  6]\n",
      " [ 6  4 10]\n",
      " [ 3  3  6]\n",
      " [ 2  3  5]], shape=(10, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "dice1 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32)) # 7 is excluded\n",
    "dice2 = tf.Variable(tf.random.uniform([10, 1], minval=1, maxval=7, dtype=tf.int32))\n",
    "# We may add dice1 and dice2 since they share the same shape and size.\n",
    "dice_sum = dice1 + dice2\n",
    "# We've got three separate 10x1 matrices. To produce a single\n",
    "# 10x3 matrix, we'll concatenate them along dimension 1.\n",
    "resulting_matrix = tf.concat(values=[dice1, dice2, dice_sum], axis=1)\n",
    "print(resulting_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ff49b-57cc-4e2f-a953-0b9b3a064972",
   "metadata": {},
   "source": [
    "Finding the indices of the largest and smallest element\n",
    "\n",
    "The signatures of the functions are as follows:\n",
    "\n",
    "- tf.argmax(input, axis=None, name=None, output_type=tf.int64 )\n",
    "\n",
    "- tf.argmin(input, axis=None, name=None, output_type=tf.int64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d91e9c5-44f7-44c2-8748-654286d5ba71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  2  11   5  42   7  19  -6 -11  29], shape=(9,), dtype=int32)\n",
      "index of max;  tf.Tensor(3, shape=(), dtype=int64)\n",
      "Max element:  42\n",
      "index of min:  7\n",
      "Min element:  -11\n",
      "tf.Tensor(\n",
      "[[  2  11   5]\n",
      " [ 42   7  19]\n",
      " [ -6 -11  29]], shape=(3, 3), dtype=int32)\n",
      "indices of max down rows;  [1 0 2]\n",
      "indices of min down rows ;  [2 2 0]\n",
      "tf.Tensor(\n",
      "[[  2  11   5]\n",
      " [ 42   7  19]\n",
      " [ -6 -11  29]], shape=(3, 3), dtype=int32)\n",
      "indices of max across cols:  [1 0 2]\n",
      "indices of min across cols:  [0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 1-D tensor\n",
    "t5 = tf.constant([2, 11, 5, 42, 7, 19, -6, -11, 29])  # vertical tensor with 9 rows\n",
    "print(t5)\n",
    "\n",
    "\n",
    "i = tf.argmax(input=t5)  # argmax means index of maximum value\n",
    "print('index of max; ', i)\n",
    "print('Max element: ',t5[i].numpy())\n",
    "\n",
    "\n",
    "i = tf.argmin(input=t5,axis=0).numpy() # argmin means index of minimum value\n",
    "print('index of min: ', i)\n",
    "print('Min element: ',t5[i].numpy())\n",
    "\n",
    "\n",
    "t6 = tf.reshape(t5, [3,3])\n",
    "print(t6)\n",
    "\n",
    "\n",
    "i = tf.argmax(input=t6,axis=0).numpy() # max arg down rows\n",
    "print('indices of max down rows; ', i)\n",
    "\n",
    "i = tf.argmin(input=t6,axis=0).numpy() # min arg down rows\n",
    "print('indices of min down rows ; ',i)\n",
    "print(t6)\n",
    "\n",
    "i = tf.argmax(input=t6,axis=1).numpy() # max arg across cols\n",
    "print('indices of max across cols: ',i)\n",
    "\n",
    "i = tf.argmin(input=t6,axis=1).numpy() # min arg across cols\n",
    "print('indices of min across cols: ',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75d7f0-ea78-45a8-9b0d-8d9daaee760c",
   "metadata": {},
   "source": [
    "### Saving and restoring tensor values using a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b44c2b70-0bde-4727-a7f5-69480505e086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 4) dtype=int32, numpy=\n",
      "array([[ 1,  3,  5,  7],\n",
      "       [11, 13, 17, 19]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "# here we reassign the certain stored value to the variable \n",
    "variable = tf.Variable([[1,3,5,7],[11,13,17,19]])\n",
    "checkpoint= tf.train.Checkpoint(var=variable)\n",
    "save_path = checkpoint.save('./vars')\n",
    "variable.assign([[0,0,0,0],[0,0,0,0]])  \n",
    "variable\n",
    "checkpoint.restore(save_path)\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5443635b-a44c-4165-9676-cd4c02b4f9c1",
   "metadata": {},
   "source": [
    "### Using tf.function\n",
    "\n",
    "tf.function is a function that will take a Python function and return a TensorFlow graph. The advantage of this is that graphs can apply optimizations and exploit parallelism in the Python function (func). tf.function is new to TensorFlow 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70933d60-7926-4618-9e53-7b4c20739564",
   "metadata": {},
   "source": [
    "Its signature is as follows:\n",
    "\n",
    "- tf.function( func=None, input_signature=None, autograph=True, experimental_autograph_options=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee86bfb9-201f-40fa-9607-fa815cfc635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, y):             # mean of [( x^2 * 5 ), y^2 ]\n",
    "    return tf.reduce_mean(input_tensor=tf.multiply(x ** 2, 5) + y**2)\n",
    "\n",
    "f2 = tf.function(f1)  # f2 is graph\n",
    "x = tf.constant([4., -5.])\n",
    "y = tf.constant([2., 3.])\n",
    "\n",
    "# f1 and f2 return the same value, but f2 executes as a TensorFlow graph\n",
    "assert f1(x,y).numpy() == f2(x,y).numpy()\n",
    "#The assert passes, so there is no output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ef299-33a6-4d32-b134-9523648ddb7c",
   "metadata": {},
   "source": [
    "### Calculate the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966c8030-fb4e-4ff5-9807-51010ca4039f",
   "metadata": {},
   "source": [
    "GradientTape\n",
    "- Another difference from numpy is that it can automatically track the gradient of any variable.\n",
    "\n",
    "- Open one GradientTape and tape.watch() track variables through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c8e3dd67-dd49-4ee6-86dc-1471f14e8c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.469929    0.89920384]\n",
      " [-0.66446567 -0.79767007]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal(shape=(2,2))\n",
    "b = tf.random.normal(shape=(2,2))\n",
    "\n",
    "with tf.GradientTape() as tape:  # monitor the gradient\n",
    "    tape.watch(a)  # here we are calculating its gradient\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))   # square root of (a^2 + b^2)\n",
    "    dc_da = tape.gradient(c,a)  # differentiate w.r.t a\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f662c-a689-4722-beec-2ab9e1bf547f",
   "metadata": {},
   "source": [
    "For all variables, the calculation is tracked by default and used to find the gradient, so do not usetape.watch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca5a2371-bca2-4b1e-aa59-b0fc9afb70e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-0.469929    0.89920384]\n",
      " [-0.66446567 -0.79767007]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(a)\n",
    "with tf.GradientTape() as tape:  # since it is a variable so we dont have to watch a\n",
    "    c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "    dc_da = tape.gradient(c,a)    # differentiate w.r.t a\n",
    "    print(dc_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c642a-98a9-401e-b50d-8701b3a0df1d",
   "metadata": {},
   "source": [
    "You can GradientTapefind higher-order derivatives by opening a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "380ccadb-1ad7-4ec4-97ec-8833ffe55a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.4264985  0.6867533 ]\n",
      " [0.44663432 0.5015956 ]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as outer_tape:  # outer tape is second order derivative \n",
    "    with tf.GradientTape() as tape:  # internal tape is first order derivative \n",
    "        c = tf.sqrt(tf.square(a)+tf.square(b))\n",
    "        dc_da = tape.gradient(c,a)\n",
    "    d2c_d2a = outer_tape.gradient(dc_da,a)  # derivarive w.r.t a of a derivative dc_da (double derivative)\n",
    "    print(d2c_d2a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e8d78-7625-4d91-973c-619f738c790f",
   "metadata": {},
   "source": [
    "### Keras - A High-Level API for TensorFlow 2\n",
    "\n",
    "<img src=\"https://3.bp.blogspot.com/-QZVBl08fmPk/XhO909Ha1dI/AAAAAAAACZI/q1a1UykGKe0KDUZ_ZITtWmM7bBJFRrvPQCLcBGAsYHQ/s1600/tensorflowkeras.jpg\" width=\"600\" \n",
    "     height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b924e3-d982-41ba-980c-3f1368c898f6",
   "metadata": {},
   "source": [
    "## The Keras Sequential model\n",
    "To build a Keras Sequential model, you add layers to it in the same order that you want the computations to be undertaken by the network.\n",
    "\n",
    "After you have built your model, you compile it; this optimizes the computations that are to be undertaken, and is where you allocate the optimizer and the loss function you want your model to use.\n",
    "\n",
    "The next stage is to fit the model to the data. This is commonly known as training the model, and is where all the computations take place. It is possible to present the data to the model either in batches, or all at once.\n",
    "\n",
    "Next, you evaluate your model to establish its accuracy, loss, and other metrics. Finally, having trained your model, you can use it to make predictions on new data. So, the workflow is: build, compile, fit, evaluate, make predictions. There are two ways to create a Sequential model. Let's take a look at each of them.\n",
    "\n",
    "## The first way to create a Sequential model\n",
    "Firstly, you can pass a list of layer instances to the constructor, as in the following example. For now, we will just explain enough to allow you to understand what is happening here.\n",
    "\n",
    "Acquire the data. MNIST is a dataset of hand-drawn numerals, each on a 28 x 28 pixel grid. Every individual data point is an unsigned 8-bit integer (uint8), as are the labels:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7a9778-feb1-4de6-8c2d-b4903a89e746",
   "metadata": {},
   "source": [
    "### Loading the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3cb78cd5-4897-4e3d-9475-19771dfbcdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_x,train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e05eda-1d24-4155-b759-8c5c319a3837",
   "metadata": {},
   "source": [
    "### Definning the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f4ece0b4-2537-4e50-b661-e51377e0854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=10\n",
    "batch_size = 32 # 32 is default in fit method but specify anyway"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571fab3-9eb5-45b7-b8eb-1f2437a89b30",
   "metadata": {},
   "source": [
    "Next, normalize all the data points (x) to be in the float range zero to one, and of the float32 type.\n",
    "\n",
    "Also, cast the labels (y) to int64, as required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5fb86953-3625-41b8-93d7-dd7971de3870",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x = tf.cast(train_x/255.0, tf.float32), tf.cast(test_x/255.0, tf.float32)\n",
    "train_y, test_y = tf.cast(train_y,tf.int64),tf.cast(test_y,tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437066e6-62ca-4032-b3be-18a7d1a87a23",
   "metadata": {},
   "source": [
    "### Building the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89e25ed1-0176-45f7-8132-82887c8826d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistmodel1 = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Flatten(),\n",
    "tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
    "tf.keras.layers.Dropout(0.2),\n",
    "tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c75b4-1dff-4a2b-bb16-28957bd01625",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2a782f9-7e66-4980-8d6d-f2c6721ad5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = tf.keras.optimizers.Adam()\n",
    "mnistmodel1.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dec306-2a0f-4ddd-9294-668085853baa",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e8c9867-8ffa-41a5-a459-f6e40963716f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8922 - loss: 0.3676\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1078\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0743\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0562\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f783fd326e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel1.fit(train_x, train_y, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd523ba4-b20a-4bbf-8d66-dca5cd95b9a5",
   "metadata": {},
   "source": [
    "### Evaluate the mnistmodel1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c4ed494-4d8d-4f28-835d-d869eb107837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9767 - loss: 0.0733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06729210913181305, 0.9793999791145325]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel1.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b798eb-3af9-453e-b3d5-102bca3a7e06",
   "metadata": {},
   "source": [
    "This represents a loss of 0.09 and an accuracy of 0.9801 on the test data.\n",
    "\n",
    "An accuracy of 0.98 means that out of 100 test data points, 98 were, on average, correctly identified by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0aaad6-7f3b-4dc3-b3e0-cb2dfccf2593",
   "metadata": {},
   "source": [
    "The second way to create a Sequential model The alternative to passing a list of layers to the Sequential model's constructor is to use the add method, as follows, for the same architecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a11bff-f7c8-4842-a2b0-00d5afccd4c1",
   "metadata": {},
   "source": [
    "### Building the Architecture & Compiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99be4caf-0915-4708-9b4a-5b4135f9145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistmodel2 = tf.keras.models.Sequential();\n",
    "mnistmodel2.add(tf.keras.layers.Flatten())\n",
    "mnistmodel2.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "mnistmodel2.add(tf.keras.layers.Dropout(0.2))\n",
    "mnistmodel2.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "mnistmodel2.compile (optimizer= tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e059d-aa99-454c-9ed3-b91cb44dbff0",
   "metadata": {},
   "source": [
    "### Fitting the mnistmodel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b4e476b-0b43-49db-bdfc-acaf22607216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.4170\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9657 - loss: 0.1178\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9763 - loss: 0.0775\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9829 - loss: 0.0580\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9857 - loss: 0.0459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f783fd30e20>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel2.fit(train_x, train_y, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9992d0b-8ede-4505-a254-c7deba1b1726",
   "metadata": {},
   "source": [
    "### Evaluate the mnistmodel2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "42c33bc7-055b-47d4-9e6a-716788db907b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9793 - loss: 0.0730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06176718696951866, 0.9821000099182129]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel2.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b272b65-de5e-4ee7-933b-962f4660cf64",
   "metadata": {},
   "source": [
    "### The Keras functional API\n",
    "The functional API lets you build much more complex architectures than the simple linear stack of Sequential models we have seen previously. It also supports more advanced models. These models include multi-input and multi-output models, models with shared layers, and models with residual connections.\n",
    "\n",
    "Here is a short example, with an identical architecture to the previous two, of the use of the functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c053fb9e-3f8e-430d-be7b-788cfcedadcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(train_x,train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "train_x, test_x = train_x/255.0, test_x/255.0\n",
    "\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507f6ca5-0fde-4434-8ea3-ad70d9b7d2cb",
   "metadata": {},
   "source": [
    "### Building the Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27ef6b91-9c59-4bd2-8c4b-ee93b380cad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(28,28)) # Returns a 'placeholder' tensor\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(512, activation='relu',name='d1')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "predictions = tf.keras.layers.Dense(10,activation=tf.nn.softmax, name='d2')(x)\n",
    "mnistmodel3 = tf.keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0068b4-8ceb-479f-a708-fcb1c37f05c6",
   "metadata": {},
   "source": [
    "### Compile & Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ebf1863c-91fc-4f83-a602-1a7d74dd8f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.3625\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.1074\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0726\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0567\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0427\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0358\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0281\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0257\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0229\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f780054fe20>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimiser = tf.keras.optimizers.Adam()\n",
    "mnistmodel3.compile (optimizer= optimiser, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "mnistmodel3.fit(train_x, train_y, batch_size=32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10eacdf-81df-49ed-9cb0-5285cfb803a2",
   "metadata": {},
   "source": [
    "### Evaluate the mnistmodel3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "968590ae-3c86-4e3c-b5e7-22b0a40c4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9771 - loss: 0.0929\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08013499528169632, 0.980400025844574]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel3.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88426eb-8ea4-49e1-b437-10243b9b1e56",
   "metadata": {},
   "source": [
    "### Subclassing the Keras Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "154a52be-973b-442e-8080-f94914c967db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44451333-31bd-44e8-ac57-82a9477d2b7b",
   "metadata": {},
   "source": [
    "### Building the subclass architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "738c2043-cadb-49ab-8078-782ac6c9b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        # Define your layers here.\n",
    "        inputs = tf.keras.Input(shape=(28,28)) # Returns a placeholder tensor\n",
    "        self.x0 = tf.keras.layers.Flatten()\n",
    "        self.x1 = tf.keras.layers.Dense(512, activation='relu',name='d1')\n",
    "        self.x2 = tf.keras.layers.Dropout(0.2)\n",
    "        self.predictions = tf.keras.layers.Dense(10,activation=tf.nn.softmax, name='d2')\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "    # This is where to define your forward pass\n",
    "    # using the layers previously defined in `__init__`\n",
    "        x = self.x0(inputs)\n",
    "        x = self.x1(x)\n",
    "        x = self.x2(x)\n",
    "        return self.predictions(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b8780876-bf05-448d-a85e-c4a0799b821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnistmodel4 = MNISTModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5348a-8bb7-4e9b-9418-3dbd61859a2c",
   "metadata": {},
   "source": [
    "### Compile & Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7056e852-4ca0-4faa-ace6-aab0ff6c5678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.3384\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9726 - loss: 0.0896\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0543\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0350\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0245\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0187\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9950 - loss: 0.0154\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9949 - loss: 0.0149\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0108\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f783fda2ec0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch = len(train_x)//batch_size\n",
    "print(steps_per_epoch)\n",
    "mnistmodel4.compile (optimizer= tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "mnistmodel4.fit(train_x, train_y, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60387096-c83e-4cd6-a357-d62967f8b272",
   "metadata": {},
   "source": [
    "### Evaluate the mnistmodel4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5672832e-7c98-4c7e-8259-f985422692c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9749 - loss: 0.1159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09564366936683655, 0.9786999821662903]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnistmodel4.evaluate(test_x, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
